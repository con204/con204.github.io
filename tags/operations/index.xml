<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>operations on Amazon EKS Workshop</title>
    <link>/tags/operations/</link>
    <description>Recent content in operations on Amazon EKS Workshop</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 27 Jan 2020 08:30:11 -0700</lastBuildDate><atom:link href="/tags/operations/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Deploying Jenkins</title>
      <link>/intermediate/210_jenkins/</link>
      <pubDate>Tue, 07 Aug 2018 08:30:11 -0700</pubDate>
      
      <guid>/intermediate/210_jenkins/</guid>
      <description>Deploy Jenkins In this Chapter, we will deploy Jenkins using the Helm package manager we installed in the Helm module and the OIDC identity provider we setup in the [IAM Roles for Service Accounts module]({{ ref &amp;ldquo;beginner/110_irsa&amp;rdquo;}}).</description>
    </item>
    
    <item>
      <title>CI/CD with CodePipeline</title>
      <link>/intermediate/220_codepipeline/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/intermediate/220_codepipeline/</guid>
      <description>CI/CD with CodePipeline Continuous integration (CI) and continuous delivery (CD) are essential for deft organizations. Teams are more productive when they can make discrete changes frequently, release those changes programmatically and deliver updates without disruption.
In this module, we will build a CI/CD pipeline using AWS CodePipeline. The CI/CD pipeline will deploy a sample Kubernetes service, we will make a change to the GitHub repository and observe the automated delivery of this change to the cluster.</description>
    </item>
    
    <item>
      <title>Logging with Elasticsearch, Fluent Bit, and Kibana (EFK)</title>
      <link>/intermediate/230_logging/</link>
      <pubDate>Tue, 21 Jul 2020 22:23:34 -0400</pubDate>
      
      <guid>/intermediate/230_logging/</guid>
      <description>Implement Logging with EFK In this Chapter, we will deploy a common Kubernetes logging pattern which consists of the following:
  Fluent Bit: an open source and multi-platform Log Processor and Forwarder which allows you to collect data/logs from different sources, unify and send them to multiple destinations. It&amp;rsquo;s fully compatible with Docker and Kubernetes environments.
  Amazon Elasticsearch Service: a fully managed service that makes it easy for you to deploy, secure, and run Elasticsearch cost effectively at scale.</description>
    </item>
    
    <item>
      <title>Monitoring using Prometheus and Grafana</title>
      <link>/intermediate/240_monitoring/</link>
      <pubDate>Sun, 14 Oct 2018 09:27:46 -0400</pubDate>
      
      <guid>/intermediate/240_monitoring/</guid>
      <description>Monitoring using Prometheus and Grafana In this Chapter, we will deploy Prometheus and Grafana to monitor Kubernetes cluster
What is Prometheus? Prometheus is an open-source systems monitoring and alerting toolkit originally built at SoundCloud. Since its inception in 2012, many companies and organizations have adopted Prometheus, and the project has a very active developer and user community. It is now a standalone open source project and maintained independently of any company.</description>
    </item>
    
    <item>
      <title>Monitoring using Pixie</title>
      <link>/intermediate/241_pixie/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/intermediate/241_pixie/</guid>
      <description>Monitoring using Pixie In this chapter, we will deploy Pixie to monitor an application on a Kubernetes cluster.
What is Pixie? Pixie is an open-source observability platform for Kubernetes. It helps developers explore, monitor and debug their applications. Pixie’s features include:
Progressive instrumentation
Pixie collects full-body request traces, system resource metrics, and Kubernetes events right out of box. Pixie&amp;rsquo;s auto-instrumentation capabilities require no code changes by the user and consume less than 5% overhead, because it powered by eBPF*.</description>
    </item>
    
    <item>
      <title>Tracing with X-Ray</title>
      <link>/intermediate/245_x-ray/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/intermediate/245_x-ray/</guid>
      <description>Tracing with X-Ray As distributed systems evolve, monitoring and debugging services becomes challenging. Container-orchestration platforms like Kubernetes solve a lot of problems, but they also introduce new challenges for developers and operators in understanding how services interact and where latency exists. AWS X-Ray helps developers analyze and debug distributed services.
In this module, we are going to deploy the X-Ray agent as a DaemonSet, deploy sample front-end and back-end services that are instrumented with the X-Ray SDK, make some sample requests and then examine the traces and service maps in the AWS Management Console.</description>
    </item>
    
    <item>
      <title>Monitoring using Amazon Managed Service for Prometheus / Grafana</title>
      <link>/intermediate/246_monitoring_amp_amg/</link>
      <pubDate>Sun, 14 Oct 2018 09:27:46 -0400</pubDate>
      
      <guid>/intermediate/246_monitoring_amp_amg/</guid>
      <description>Introduction Amazon Managed Service for Prometheus (AMP) Amazon Managed Service for Prometheus is a monitoring service for metrics compatible with the open source Prometheus project, making it easier for you to securely monitor container environments. AMP is a solution for monitoring containers based on the popular Cloud Native Computing Foundation (CNCF) Prometheus project. AMP is powered by Cortex, an open source CNCF project that adds horizontal scalability to ingest, store, query, and alert on Prometheus metrics.</description>
    </item>
    
    <item>
      <title>EKS CloudWatch Container Insights</title>
      <link>/intermediate/250_cloudwatch_container_insights/</link>
      <pubDate>Mon, 13 Apr 2020 15:27:17 -0400</pubDate>
      
      <guid>/intermediate/250_cloudwatch_container_insights/</guid>
      <description>In this chapter we will learn and leverage the new CloudWatch Container Insights to see how you can use native CloudWatch features to monitor your EKS Cluster performance.
You can use CloudWatch Container Insights to collect, aggregate, and summarize metrics and logs from your containerized applications and microservices. Container Insights is available for Amazon Elastic Container Service, Amazon Elastic Kubernetes Service, and Kubernetes platforms on Amazon EC2. The metrics include utilization for resources such as CPU, memory, disk, and network.</description>
    </item>
    
    <item>
      <title>GitOps with Weave Flux</title>
      <link>/intermediate/260_weave_flux/</link>
      <pubDate>Sun, 14 Oct 2018 19:56:14 -0400</pubDate>
      
      <guid>/intermediate/260_weave_flux/</guid>
      <description>GitOps with Weave Flux GitOps, a term coined by Weaveworks, is a way to do continuous delivery. Git is used as single source of truth for deploying into your cluster. This is easy for a development team as they are already familiar with git and do not need to know other tools. Weave Flux is a tool that runs in your Kubernetes cluster and implements changes based on monitoring Git and image repositories.</description>
    </item>
    
    <item>
      <title>Custom Resource Definition</title>
      <link>/intermediate/270_custom_resource_definition/</link>
      <pubDate>Tue, 09 Apr 2019 00:00:00 -0300</pubDate>
      
      <guid>/intermediate/270_custom_resource_definition/</guid>
      <description>Custom Resource Definition Introduction In this Chapter, we will review the Custom Resource Definition (CRD) concept, and some examples of usage.
In Kubernetes API, a resource is an endpoint storing the API objects in a collection. As an example, the pods resource contains a collection of Pod objects.
CRD’s are extensions of Kubernetes API that stores collection of API objects of certain kind. They extend the Kubernetes API or allow you to add your own API into the cluster.</description>
    </item>
    
    <item>
      <title>Service Mesh with Istio</title>
      <link>/advanced/310_servicemesh_with_istio/</link>
      <pubDate>Tue, 13 Nov 2018 16:32:30 +0900</pubDate>
      
      <guid>/advanced/310_servicemesh_with_istio/</guid>
      <description>A service mesh is a dedicated infrastructure layer for handling service-to-service communication. It’s responsible for the reliable delivery of requests through the complex topology of services that comprise a modern, cloud native application.
Service mesh solutions have two distinct components that behave somewhat differently:
 The data planeis composed of a set of intelligent proxies (Envoy) deployed as sidecars. These proxies mediate and control all network communication between microservices along with Mixer, a general-purpose policy and telemetry hub.</description>
    </item>
    
    <item>
      <title>Patching/Upgrading your EKS Cluster</title>
      <link>/intermediate/320_eks_upgrades/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/intermediate/320_eks_upgrades/</guid>
      <description>Patching/Upgrading your EKS Cluster As EKS tracks upstream Kubernetes that means that customers can, and should, regularly upgrade their EKS so as to stay within the project&amp;rsquo;s upstream support window. This used to be the current version and two version back (n-2) - but it was recently extended to three versions back (n-3).
There is a new major version of Kubernetes every quarter which means that the Kubernetes support window has now gone from three quarters of a year to one full year.</description>
    </item>
    
    <item>
      <title>Service Mesh using AWS App Mesh</title>
      <link>/advanced/330_servicemesh_using_appmesh/</link>
      <pubDate>Mon, 27 Jan 2020 08:30:11 -0700</pubDate>
      
      <guid>/advanced/330_servicemesh_using_appmesh/</guid>
      <description>Meshifying with AWS App Mesh (Part 1)   Meshifying with AWS App Mesh (Part 2)   At re:invent 2018, we announced AWS App Mesh, a service mesh that provides application-level networking to make it easy for your services to communicate with each other across multiple types of compute infrastructure. AWS App Mesh standardizes how your services communicate, giving you end-to-end visibility and ensuring high-availability for your applications.
Service meshes like AWS App Mesh help you to run and monitor HTTP and TCP services at scale.</description>
    </item>
    
    <item>
      <title>Getting Started with AWS App Mesh</title>
      <link>/intermediate/330_app_mesh/</link>
      <pubDate>Tue, 07 Aug 2018 08:30:11 -0700</pubDate>
      
      <guid>/intermediate/330_app_mesh/</guid>
      <description>AWS App Mesh on Amazon EKS   Getting Fancy with AWS App Mesh on Amazon EKS   At re:invent 2018, we announced AWS App Mesh, a service mesh that provides application-level networking to make it easy for your services to communicate with each other across multiple types of compute infrastructure. App Mesh standardizes how your services communicate, giving you end-to-end visibility and ensuring high-availability for your applications.
Service meshes like AWS App Mesh help you to run and monitor HTTP and TCP services at scale.</description>
    </item>
    
  </channel>
</rss>
